import pandas as pd
import sqlite3

# Turning the files into dataframes
df_excel = pd.read_excel('data_excel.xlsx')
df_csv = pd.read_csv('data_csv.csv')
df_json = pd.read_json('data_json.json')

# Renaming excel columns
df_excel.rename(columns={
    'OrderID':'OrderID',
    'Customer':'CustomerName',
    'Product':'ProductName',
    'Qty':'Quantity',
    'UnitPrice':'Price',
    'OrderDate':'OrderDate'
}, inplace= True)
print(df_excel.columns.values)

# Renaming csv columns
df_csv.rename(columns={
    'ID':'OrderID',
    'Name':'CustomerName',
    'Item':'ProductName',
    'Count':'Quantity',
    'PricePerUnit':'Price',
    'Date':'OrderDate'
},inplace= True)
print(df_csv.columns.values)

# Renaming json columns
df_json.rename(columns={
    "Order_ID":"OrderID",
    "Cust":"CustomerName",
    "Item_Name":"ProductName",
    "Quantity":"Quantity",
    "Price":"Price",
    "SaleDate":"OrderDate"
}, inplace= True)
print(df_json.columns.values)

# Sqlite file connection
conn = sqlite3.connect('data_orders.sqlite')
df_sql = pd.read_sql_query("SELECT * FROM WarehouseOrders", conn)

# print(df_sql.columns.values)

df_sql.rename(columns={
    'OID':'OrderID',
    'CustName':'CustomerName',
    'Prod':'ProductName',
    'Qty':'Quantity',
    'Rate':'Price',
    'OD':'OrderDate'
}, inplace= True)
print(df_sql.columns.values)

df_dict = pd.DataFrame({
    "order_no": [501, 502],
    "client": ["Ivy", "Jack"],
    "product_name": ["Tablet", "Laptop"],
    "qty_ordered": [2, 1],
    "unit_cost": [650, 1250],
    "date_of_order": pd.to_datetime(["2024-05-02", "2024-05-03"])
})

df_dict.rename(columns={
    "order_no":"OrderID",
    "client":"CustomerName",
    "product_name":"ProductName",
    "qty_ordered":"Quantity",
    "unit_cost":"Price",
    "date_of_order":"OrderDate"
}, inplace=True)
print(df_dict.columns.values)

# print(f"\n Data from Excel {df_excel.shape[0]}")
# print(f"\n Data from csv {df_csv.shape[0]}")
# print(f"\n Data from Json {df_json.shape[0]}")
# print(f"\n Data from sqllite {df_sql.shape[0]}")



df_combined = pd.concat([df_excel, df_csv, df_json,df_sql, df_dict], ignore_index=True)
print('\n Combined data are below \n')
print(df_combined)
print(df_combined.columns.values)
df_combined['OrderDate'] = pd.to_datetime(df_combined['OrderDate'], errors='coerce')
df_combined['OrderDate'] = df_combined['OrderDate'].dt.date
print(df_combined)
# df_combined.to_csv("Combined_data.csv")

# Section 1: Data Understanding & Quality
# Suggest cleanup strategies like:
# Dropping rows
# Filling with mean/median
# Using business rules
# 1. How many records are there in total after merging all sources?
print(df_combined.shape)

# 2. Are there any missing values in critical columns like Product, 
# Quantity, or UnitPrice? How would you handle them?

# Checking for Null Values
print(df_combined['ProductName'].isnull())
print(df_combined['Quantity'].isnull())
print(df_combined['Price'].isnull())
print(df_combined.duplicated().sum())

# Changing the datatypes when required
df_combined['OrderDate'] = pd.to_datetime(df_combined['OrderDate'], errors='coerce')
print(df_combined.dtypes)

# Section 2: Transformation & Aggregation
# 3. Calculate the total revenue generated by each data source. 
# How would you track the source of each row?
# Hint: Add a Source column to each individual DataFrame before merging.
# Group by Source, then sum TotalAmount.z

df_combined['TotalRevenue'] = df_combined['Quantity'] * df_combined['Price']

# # 4. What is the total quantity sold for each product?
print(df_combined.groupby('ProductName')['Quantity'].sum())

# 5. Which month had the highest total sales revenue?
df_combined['MonthlySales'] = pd.to_datetime(df_combined['OrderDate'], errors='coerce').dt.month_name()
print(df_combined['MonthlySales'])
print(df_combined.groupby('MonthlySales')['TotalRevenue'].sum().sort_values(ascending=False))

# Section 3: Business Insight
# 6. Who are the top 3 customers based on total purchase value?
print(df_combined.groupby('CustomerName')['TotalRevenue'].sum().sort_values(ascending=False))

# 7. Which product generated the highest revenue and how many orders did it receive?
print(df_combined.groupby(['ProductName', 'Quantity'])['TotalRevenue'].sum().sort_values(ascending=False))

# 8. What is the average order value (AOV) across all orders?
AOV = df_combined['TotalRevenue'].sum() / df_combined['OrderID'].nunique()
print(AOV)

# Section 4: Anomaly Detection
# 9. Identify the top 5 orders with the highest UnitPrice. Are these values realistic?
print(df_combined.groupby(['OrderID', 'ProductName'])['Price'].sum().sort_values(ascending=False).head())

# 10. Detect outliers in pricing using standard deviation method. List them and suggest actions.
print(df_combined[df_combined['Price'] > df_combined['Price'].mean() + 2 * df_combined['Price'].std()])


# ðŸ“¤ Bonus Challenge
# # Export the final DataFrame to Excel:
print(df_combined)
df_combined.to_excel("Final_Sales_Analysis.xlsx", index=False)
print("File Created Successfully")
